{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import train_test_split\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n",
      "[[  5.   4.   4.   5.   7.  10.   3.   2.   1.]\n",
      " [  3.   1.   1.   1.   2.   2.   3.   1.   1.]\n",
      " [  6.   8.   8.   1.   3.   4.   3.   7.   1.]\n",
      " [  4.   1.   1.   3.   2.   1.   3.   1.   1.]]\n",
      "(699, 9)\n",
      "(699, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('breast_cancer_wisconsin_dataset.txt', dtype ='float', delimiter=\",\")\n",
    "print np.shape(data)\n",
    "\n",
    "#  The wisconsin breast cancer data set is from the UCI ML repository\n",
    "#  It's 9 features are as follows:\n",
    "#  Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape,\n",
    "#  Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, \n",
    "#  Bland Chromatin, Normal Nucleoli, and Mitoses.\n",
    "#  Each is an integer between 1 and 10.\n",
    "#  The label is whether the tumor is malignant or benign.\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "\n",
    "X = data[:,1:10].reshape([699, 9])\n",
    "Y = data[:,10].reshape([699, 1])\n",
    "Y = np.where(Y == 2 , 1, 0)\n",
    "posLabel = '2: benign'\n",
    "negLabel = '4: malignant'\n",
    "dataset_name = 'breast_cancer_wisconsin_dataset'\n",
    "\n",
    "print X[1:5,:]\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n",
      "(178, 13)\n",
      "(178, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('wine.txt', dtype ='float', delimiter=\",\")\n",
    "print np.shape(data)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#      \"These data are the results of a chemical analysis of\n",
    "#      wines grown in the same region in Italy but derived from three\n",
    "#      different cultivars.\n",
    "#      The analysis determined the quantities of 13 constituents\n",
    "#      found in each of the three types of wines.\" - UCI repository\n",
    "#      The features are as follows: \n",
    "#      Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium\n",
    "#      Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins\n",
    "#      Color intensity, Hue, OD280/OD315 of diluted wines, Proline \n",
    "#      https://archive.ics.uci.edu/ml/datasets/wine\n",
    "\n",
    "\n",
    "X = data[:,1:].reshape([178, 13])\n",
    "Y = data[:,0].reshape([178, 1])\n",
    "Y = np.where(Y == 1 , 1, 0)\n",
    "posLabel = '1: location1'\n",
    "negLabel = '2 & 3: location2 and location3' \n",
    "dataset_name = 'wine_location'\n",
    "\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n",
      "(4898, 11)\n",
      "(4898, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('winequality_white_tab.txt', dtype ='float', delimiter=\";\")\n",
    "print np.shape(data)\n",
    "\n",
    "# \"Two datasets are included, related to red and white vinho verde wine samples,\n",
    "# from the north of Portugal. The goal is to model wine quality based\n",
    "# on physicochemical tests (see [Cortez et al., 2009])\" - UCI repository\n",
    "# It's 11 features are as follows:\n",
    "# fixed acidity, volatile acidity, citric acid, residual sugar, chlorides\n",
    "# free sulfur dioxide, total sulfur dioxide, density\n",
    "# pH, sulphates, alcohol.\n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\n",
    "\n",
    "X = data[:,0:11]\n",
    "Y = data[:,11].reshape([4898, 1])\n",
    "\n",
    "Y = np.where(Y >=5 , 1, 0)\n",
    "posLabel = 'high quality'\n",
    "negLabel = 'low quality'\n",
    "dataset_name = 'winequality_white'\n",
    "\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_mean = stats.nanmean(X,axis=0)\n",
    "inds = np.where(np.isnan(X))\n",
    "X[inds]=np.take(col_mean,inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidDistance(Xset, point_being_classified):\n",
    "    distance = np.sqrt(np.sum(np.power(Xset - point_being_classified,2),axis = 1))\n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNearestK(Xset, point_being_classified, k):\n",
    "    distance = euclidDistance(Xset,point_being_classified)\n",
    "    indecies_of_nearest_k = distance.argsort()[:k]\n",
    "    return indecies_of_nearest_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPointLabel(Xset, Yset, point_being_classified, k):\n",
    "    indecies_of_nearest_k = getNearestK(Xset, point_being_classified, k)\n",
    "    labels_of_nearest_k = Yset[indecies_of_nearest_k]\n",
    "    classification_of_point = mode(labels_of_nearest_k)[0][0]\n",
    "    return classification_of_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN(Xtrain,Xtest,ytrain,ytest,k):\n",
    "    predicted_labels = np.zeros((len(ytest)))\n",
    "    for row in range(len(ytest)):\n",
    "        point_being_classified = Xtest[row,:]\n",
    "        predicted_labels[row] = getPointLabel(Xtrain, ytrain, point_being_classified, k)\n",
    "\n",
    "    errors_list = np.where(predicted_labels != ytest, 1, 0 )\n",
    "    error = (1.0/float(len(ytest)))*np.sum(errors_list)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is KNN with kfold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: winequality_white\n",
      "This is KNN with CV with kfold =  5\n",
      "The positive label is high quality and the negative label is low quality\n",
      "The number of error calculations is 1\n",
      "The table below lists each k with their associated validation error and accuracy\n",
      "[[ 4.     0.045  0.955]\n",
      " [ 5.     0.039  0.961]\n",
      " [ 6.     0.043  0.957]]\n"
     ]
    }
   ],
   "source": [
    "kfold = 5\n",
    "knn = np.array([4,5,6])#,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "\n",
    "output_table = np.zeros((len(knn),3))\n",
    "output_table[:,0] = knn\n",
    "\n",
    "error = np.zeros((1,kfold))\n",
    "\n",
    "number_of_error_Calculations = 1\n",
    "errorCalcAverage = np.zeros((1,number_of_error_Calculations))\n",
    "errorCalcVar = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "for k_iter, knn in enumerate(knn):\n",
    "\n",
    "    for m in range(number_of_error_Calculations):\n",
    "\n",
    "        full_training_dataset_with_labels = np.hstack((X,Y))\n",
    "        np.random.shuffle(full_training_dataset_with_labels)\n",
    "        CV_set = full_training_dataset_with_labels\n",
    "\n",
    "        for i in range(kfold):\n",
    "\n",
    "            datasetDimensions = np.shape(X)\n",
    "            datasetLength = datasetDimensions[0]\n",
    "            datasetWidth = datasetDimensions[1]\n",
    "\n",
    "            batchSize = datasetLength/kfold\n",
    "            index1 = int(batchSize*i)\n",
    "            index2 = int(batchSize*(i+1)) \n",
    "\n",
    "            if i == max(range(kfold)):\n",
    "                CV_set_train = np.delete(CV_set, np.s_[index1:] ,0)\n",
    "                CV_set_test = CV_set[index1:,:]\n",
    "\n",
    "            else: \n",
    "\n",
    "                CV_set_train = np.delete(CV_set, np.s_[index1:index2] ,0)\n",
    "                CV_set_test = CV_set[index1:index2,:]\n",
    "\n",
    "\n",
    "            CV_X_train = CV_set_train[:,0:datasetWidth]\n",
    "            CV_y_train = CV_set_train[:,datasetWidth]\n",
    "\n",
    "            CV_X_test =  CV_set_test[:,0:datasetWidth]\n",
    "            CV_y_test =  CV_set_test[:,datasetWidth]\n",
    "\n",
    "\n",
    "            error[0,i] = KNN(CV_X_train, CV_X_test, CV_y_train, CV_y_test, knn)  \n",
    "\n",
    "        avgCVError = (1.0/float(kfold))*np.sum(error)\n",
    "\n",
    "        errorCalcAverage[0,m] = avgCVError\n",
    "\n",
    "    errorCalcAverageTot = (1.0/float(number_of_error_Calculations))*np.sum(errorCalcAverage)\n",
    "\n",
    "    output_table[k_iter, 1] = errorCalcAverageTot\n",
    "    output_table[k_iter, 2] = 1 - errorCalcAverageTot\n",
    "\n",
    "print \"Dataset:\", dataset_name\n",
    "print \"This is KNN with CV with kfold = \", kfold\n",
    "print \"The positive label is\", posLabel, \"and the negative label is\", negLabel   \n",
    "print \"The number of error calculations is\", number_of_error_Calculations \n",
    "print \"The table below lists each k with their associated validation error and accuracy\"\n",
    "print np.around(output_table, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is KNN with variable training/testing ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: winequality_white\n",
      "This is KNN with k =  5\n",
      "The positive label is high quality and the negative label is low quality\n",
      "The number of error calculations is 5\n",
      "The training/testing ratio is the first column\n",
      "and the testing error average is the second column\n",
      "and the testing accuracy average is the third column\n",
      "[[ 0.6    0.04   0.96 ]\n",
      " [ 0.7    0.042  0.958]\n",
      " [ 0.8    0.043  0.957]]\n"
     ]
    }
   ],
   "source": [
    "ratio_list = np.array([0.6,0.7,0.8]) #0.1,0.2,0.3,0.4,0.5,0.9,0.95\n",
    "testing_error_for_ratios = np.zeros((len(ratio_list),3))\n",
    "testing_error_for_ratios[:,0] = ratio_list \n",
    "\n",
    "knn = 5\n",
    "\n",
    "    \n",
    "for q_iter, trainingRatio in enumerate(ratio_list):\n",
    "\n",
    "    testingRatio = 1.00 - trainingRatio\n",
    "\n",
    "\n",
    "    number_of_error_Calculations = 5\n",
    "\n",
    "    error = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "    errorCalcAverage = np.zeros((1,number_of_error_Calculations))\n",
    "    errorCalcVar = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "\n",
    "    for i in range(number_of_error_Calculations):\n",
    "\n",
    "        dataset_with_labels = np.hstack((X,Y))\n",
    "        np.random.shuffle(dataset_with_labels)\n",
    "\n",
    "        datasetDimensions = np.shape(X)\n",
    "        datasetLength = datasetDimensions[0]\n",
    "        datasetWidth = datasetDimensions[1]\n",
    "\n",
    "        trainingSetLength = int(datasetLength*trainingRatio)\n",
    "        trainingSetWidth = datasetWidth \n",
    "\n",
    "        Xy_train = dataset_with_labels[0:trainingSetLength,:]\n",
    "        Xy_test = dataset_with_labels[trainingSetLength:,:]\n",
    "\n",
    "        X_train = Xy_train[:,0:trainingSetWidth]\n",
    "        y_train = Xy_train[:,trainingSetWidth]\n",
    "\n",
    "        X_test = Xy_test[:,0:trainingSetWidth]\n",
    "        y_test = Xy_test[:,trainingSetWidth]\n",
    "\n",
    "        error[0,i] = KNN(X_train, X_test, y_train, y_test, knn)\n",
    "\n",
    "    # here the average and varience of errors is calculated from a bunch of different trained svms each trained on a \n",
    "    # the same dataset but where the full data set is randomized and then split into training and testing sets\n",
    "    # so each training and testing set that each SVM is trained on is different. These metrics below are the average\n",
    "    # and varience of the errors that are produced from the different svms. \n",
    "\n",
    "\n",
    "    average_of_errors = (1.0/float(number_of_error_Calculations) )* np.sum(error)\n",
    "    \n",
    "    testing_error_for_ratios[q_iter,1] = average_of_errors\n",
    "    testing_error_for_ratios[q_iter,2] = 1- average_of_errors\n",
    "\n",
    "print \"Dataset:\", dataset_name\n",
    "print \"This is KNN with k = \", knn #,\" and with training/testing ratio: \", trainingRatio, testingRatio\n",
    "print \"The positive label is\", posLabel, \"and the negative label is\", negLabel \n",
    "print \"The number of error calculations is\", number_of_error_Calculations\n",
    "print \"The training/testing ratio is the first column\"\n",
    "print \"and the testing error average is the second column\"\n",
    "print \"and the testing accuracy average is the third column\"\n",
    "print np.around(testing_error_for_ratios, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
