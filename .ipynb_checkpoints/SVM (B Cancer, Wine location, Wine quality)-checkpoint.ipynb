{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.stats as stats\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('breast_cancer_wisconsin_dataset.txt', dtype ='float', delimiter=\",\")\n",
    "print np.shape(data)\n",
    "\n",
    "#  The wisconsin breast cancer data set is from the UCI ML repository\n",
    "#  It's 9 features are as follows:\n",
    "#  Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape,\n",
    "#  Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, \n",
    "#  Bland Chromatin, Normal Nucleoli, and Mitoses.\n",
    "#  Each is an integer between 1 and 10.\n",
    "#  The label is whether the tumor is malignant or benign.\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names\n",
    "\n",
    "X = data[:,1:10].reshape([699, 9])\n",
    "Y = data[:,10].reshape([699, 1])\n",
    "Y = np.where(Y == 2 , 1, 0)\n",
    "posLabel = '2: benign'\n",
    "negLabel = '4: malignant'\n",
    "dataset_name = 'breast_cancer_wisconsin_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n",
      "(178, 13)\n",
      "(178, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('wine.txt', dtype ='float', delimiter=\",\")\n",
    "print np.shape(data)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#      \"These data are the results of a chemical analysis of\n",
    "#      wines grown in the same region in Italy but derived from three\n",
    "#      different cultivars.\n",
    "#      The analysis determined the quantities of 13 constituents\n",
    "#      found in each of the three types of wines.\" - UCI repository\n",
    "#      The features are as follows: \n",
    "#      Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium\n",
    "#      Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins\n",
    "#      Color intensity, Hue, OD280/OD315 of diluted wines, Proline \n",
    "#      https://archive.ics.uci.edu/ml/datasets/wine\n",
    "\n",
    "X = data[:,1:].reshape([178, 13])\n",
    "Y = data[:,0].reshape([178, 1])\n",
    "\n",
    "Y = np.where(Y == 1 , 1, 0)\n",
    "posLabel = '1: location1'\n",
    "negLabel = '2 & 3: location2 and location3'\n",
    "dataset_name = 'wine_location'\n",
    "\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n",
      "(4898, 11)\n",
      "(4898, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('winequality_white_tab.txt', dtype ='float', delimiter=\";\")\n",
    "print np.shape(data)\n",
    "\n",
    "# \"[This dataset contains] white vinho verde wine samples,\n",
    "# from the north of Portugal. The goal is to model wine quality based\n",
    "# on physicochemical tests (see [Cortez et al., 2009])\" - UCI repository\n",
    "# It's 11 features are as follows:\n",
    "# fixed acidity, volatile acidity, citric acid, residual sugar, chlorides\n",
    "# free sulfur dioxide, total sulfur dioxide, density\n",
    "# pH, sulphates, alcohol.\n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names\n",
    "\n",
    "X = data[:,0:11]#.reshape([4898, 11])\n",
    "Y = data[:,11].reshape([4898, 1])\n",
    "Y = np.where(Y >=5 , 1, 0)\n",
    "posLabel = 'high quality'\n",
    "negLabel = 'low quality'\n",
    "dataset_name = 'winequality_white'\n",
    "\n",
    "# Quality labels scale from 0 to 10\n",
    "np.array([1,10,20,50,100,150,200,250,300])\n",
    "print np.shape(X)\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_mean = stats.nanmean(X,axis=0)\n",
    "inds = np.where(np.isnan(X))\n",
    "X[inds]=np.take(col_mean,inds[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM on full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: winequality_white\n",
      "This is SVC with linear kernel and kfold CV with k = 5\n",
      "The positive label is high quality and the negative label is low quality\n",
      "The number of error calculations per parameter set is 1\n",
      "The first column is C\n",
      "The second column is the average validation error\n",
      "The third column is the average validation accuracy\n",
      "[[  1.      0.037   0.963]\n",
      " [ 10.      0.037   0.963]\n",
      " [ 20.      0.037   0.963]]\n"
     ]
    }
   ],
   "source": [
    "C_list = np.array([1, 10, 20])\n",
    "#C_list = np.array([150,200,250,300])\n",
    "#C_list = np.array([350,400,450,500])\n",
    "C_error_list = np.zeros((len(C_list),3))\n",
    "C_error_list[:,0] = C_list\n",
    "\n",
    "for diter, C in enumerate(C_list):\n",
    "\n",
    "    kfold = 5\n",
    "\n",
    "    error = np.zeros((1,kfold))\n",
    "\n",
    "    number_of_error_Calculations = 1\n",
    "    errorCalcAverage = np.zeros((1,number_of_error_Calculations))\n",
    "    errorCalcVar = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "    for m in range(number_of_error_Calculations):\n",
    "\n",
    "        full_training_dataset_with_labels = np.hstack((X,Y))\n",
    "        np.random.shuffle(full_training_dataset_with_labels)\n",
    "        CV_set = full_training_dataset_with_labels\n",
    "\n",
    "        for i in range(kfold):\n",
    "\n",
    "            datasetDimensions = np.shape(X)\n",
    "            datasetLength = datasetDimensions[0]\n",
    "            datasetWidth = datasetDimensions[1]\n",
    "\n",
    "            batchSize = datasetLength/kfold\n",
    "            index1 = int(batchSize*i)\n",
    "            index2 = int(batchSize*(i+1)) # check this. shouldn't it be (int(batchSize*i)+1)?\n",
    "\n",
    "            if i == max(range(kfold)):\n",
    "                CV_set_train = np.delete(CV_set, np.s_[index1:] ,0)\n",
    "                CV_set_test = CV_set[index1:,:]\n",
    "\n",
    "            else: \n",
    "\n",
    "                CV_set_train = np.delete(CV_set, np.s_[index1:index2] ,0)\n",
    "                CV_set_test = CV_set[index1:index2,:]\n",
    "\n",
    "\n",
    "            CV_X = CV_set_train[:,0:datasetWidth]\n",
    "            CV_y = CV_set_train[:,datasetWidth]\n",
    "\n",
    "            #C = 1\n",
    "\n",
    "            CV_X_test =  CV_set_test[:,0:datasetWidth]\n",
    "            CV_y_test =  CV_set_test[:,datasetWidth]\n",
    "\n",
    "            clf = svm.SVC(C=C, kernel='linear')\n",
    "            clf.fit(CV_X, CV_y)  \n",
    "\n",
    "            Fx = clf.predict(CV_X_test)\n",
    "\n",
    "            error[0,i] = (1.0/float(len(CV_y_test)))*np.sum(np.where(Fx == CV_y_test, 0, 1))\n",
    "\n",
    "        avgCVError = (1.0/float(kfold))*np.sum(error)\n",
    "\n",
    "        errorCalcAverage[0,m] = avgCVError\n",
    "\n",
    "    errorCalcAverageTot = (1.0/float(number_of_error_Calculations))*np.sum(errorCalcAverage)\n",
    "\n",
    "    \n",
    "    C_error_list[diter,1] = errorCalcAverageTot\n",
    "    C_error_list[diter,2] = 1 - errorCalcAverageTot\n",
    "    \n",
    "print \"Dataset:\", dataset_name\n",
    "print \"This is SVC with linear kernel and kfold CV with k =\", kfold#, \"and C =\", C \n",
    "print \"The positive label is\", posLabel, \"and the negative label is\", negLabel   \n",
    "print \"The number of error calculations per parameter set is\", number_of_error_Calculations \n",
    "print \"The first column is C\"\n",
    "print \"The second column is the average validation error\"\n",
    "print \"The third column is the average validation accuracy\"\n",
    "np.set_printoptions(suppress=True)\n",
    "print np.around(C_error_list,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Radial Basis Function (RBF) SVM on full training set. Selecting parameters C and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: winequality_white\n",
      "This is SVC with rbf kernel and kfold CV with k = 5\n",
      "The positive label is high quality and the negative label is low quality\n",
      "The number of error calculations per parameter set is 5\n",
      "The left column is C and the top row is right column is the average error for that C\n",
      "[[  0.      0.8     0.9     1.      1.1  ]\n",
      " [  1.      0.034   0.035   0.034   0.034]\n",
      " [ 10.      0.034   0.034   0.034   0.034]]\n"
     ]
    }
   ],
   "source": [
    "C_list = np.array([1,10])#,20,50])#,100,150,200,250,300])\n",
    "\n",
    "#gamma_list = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "gamma_list = np.array([0.8, 0.9, 1, 1.1])\n",
    "#gamma_list = np.array([1,10,20,50,100,150,200,250,300])\n",
    "#gamma_list = np.array([0.01,0.02,0.03,0.04,0.05,0.06,0.07]) #,0.08,0.09])\n",
    "\n",
    "C_error_list = np.zeros(((len(C_list)+1),(len(gamma_list)+1)))\n",
    "C_error_list[0,1:] = gamma_list\n",
    "C_error_list[1:,0] = C_list\n",
    "\n",
    "for gamma_iter, gamma in enumerate(gamma_list):\n",
    "\n",
    "    for riter, C in enumerate(C_list):\n",
    "\n",
    "        kfold = 5\n",
    "\n",
    "        error = np.zeros((1,kfold))\n",
    "\n",
    "        number_of_error_Calculations = 5\n",
    "        errorCalcAverage = np.zeros((1,number_of_error_Calculations))\n",
    "        errorCalcVar = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "        for m in range(number_of_error_Calculations):\n",
    "\n",
    "            full_training_dataset_with_labels = np.hstack((X,Y))\n",
    "            np.random.shuffle(full_training_dataset_with_labels)\n",
    "            CV_set = full_training_dataset_with_labels\n",
    "\n",
    "            for i in range(kfold):\n",
    "\n",
    "                datasetDimensions = np.shape(X)\n",
    "                datasetLength = datasetDimensions[0]\n",
    "                datasetWidth = datasetDimensions[1]\n",
    "\n",
    "                batchSize = datasetLength/kfold\n",
    "                index1 = int(batchSize*i)\n",
    "                index2 = int(batchSize*(i+1))\n",
    "\n",
    "                if i == max(range(kfold)):\n",
    "                    CV_set_train = np.delete(CV_set, np.s_[index1:] ,0)\n",
    "                    CV_set_test = CV_set[index1:,:]\n",
    "\n",
    "                else: \n",
    "\n",
    "                    CV_set_train = np.delete(CV_set, np.s_[index1:index2] ,0)\n",
    "                    CV_set_test = CV_set[index1:index2,:]\n",
    "\n",
    "\n",
    "                CV_X = CV_set_train[:,0:datasetWidth]\n",
    "                CV_y = CV_set_train[:,datasetWidth]\n",
    "\n",
    "                CV_X_test =  CV_set_test[:,0:datasetWidth]\n",
    "                CV_y_test =  CV_set_test[:,datasetWidth]\n",
    "\n",
    "                #C = 2\n",
    "                #gamma = 0.1\n",
    "\n",
    "                clf = svm.SVC(C=C, kernel='rbf', gamma = gamma)\n",
    "                clf.fit(CV_X, CV_y)  \n",
    "\n",
    "                Fx = clf.predict(CV_X_test)\n",
    "\n",
    "                error[0,i] = (1.0/float(len(CV_y_test)))*np.sum(np.where(Fx == CV_y_test, 0, 1))\n",
    "\n",
    "            avgCVError = (1.0/float(kfold))*np.sum(error)\n",
    "\n",
    "            varCVError = (1.0/float(kfold))*np.sum(np.square((error-avgCVError)))\n",
    "\n",
    "            errorCalcAverage[0,m] = avgCVError\n",
    "\n",
    "        errorCalcAverageTot = (1.0/float(number_of_error_Calculations))*np.sum(errorCalcAverage)\n",
    "\n",
    "        C_error_list[(riter+1), (gamma_iter+1)] = errorCalcAverageTot\n",
    "    \n",
    "print \"Dataset:\", dataset_name\n",
    "print \"This is SVC with rbf kernel and kfold CV with k =\", kfold#, \"and gamma =\", gamma, \".\"\n",
    "print \"The positive label is\", posLabel, \"and the negative label is\", negLabel \n",
    "print \"The number of error calculations per parameter set is\", number_of_error_Calculations  \n",
    "print \"The left column is C and the top row is right column is the average error for that C\"\n",
    "np.set_printoptions(suppress=True)\n",
    "parameter_output=np.around(C_error_list,3)\n",
    "print parameter_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with the different sizes of training and testing data to see how they effect the classification results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: winequality_white\n",
      "This is SVC with linear kernel\n",
      "The positive label is high quality and the negative label is low quality\n",
      "C = 1\n",
      "The number of error calculations per parameter set is 5\n",
      "The training/testing ratio is the first column\n",
      "The testing error average is the second column\n",
      "The testing accuracy average is the third column\n",
      "[[ 0.6    0.034  0.966]\n",
      " [ 0.7    0.042  0.958]\n",
      " [ 0.8    0.036  0.964]]\n"
     ]
    }
   ],
   "source": [
    "ratio_list = np.array([0.6,0.7,0.8])#0.1,0.2,0.3,0.4,0.5,0.9,0.95\n",
    "testing_error_for_ratios = np.zeros((len(ratio_list),3))\n",
    "testing_error_for_ratios[:,0] = ratio_list \n",
    "\n",
    "C = 1\n",
    "gamma = 0.7\n",
    "kernel = 'linear'\n",
    "\n",
    "for q_iter, trainingRatio in enumerate(ratio_list):\n",
    "\n",
    "    testingRatio = 1.00 - trainingRatio\n",
    "\n",
    "\n",
    "    number_of_error_Calculations = 5\n",
    "\n",
    "    error = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "    errorCalcAverage = np.zeros((1,number_of_error_Calculations))\n",
    "    errorCalcVar = np.zeros((1,number_of_error_Calculations))\n",
    "\n",
    "\n",
    "    for i in range(number_of_error_Calculations):\n",
    "\n",
    "        dataset_with_labels = np.hstack((X,Y))\n",
    "        np.random.shuffle(dataset_with_labels)\n",
    "\n",
    "        datasetDimensions = np.shape(X)\n",
    "        datasetLength = datasetDimensions[0]\n",
    "        datasetWidth = datasetDimensions[1]\n",
    "\n",
    "        trainingSetLength = int(datasetLength*trainingRatio)\n",
    "        trainingSetWidth = datasetWidth \n",
    "\n",
    "        Xy_train = dataset_with_labels[0:trainingSetLength,:]\n",
    "        Xy_test = dataset_with_labels[trainingSetLength:,:]\n",
    "\n",
    "        X_train = Xy_train[:,0:trainingSetWidth]\n",
    "        y_train = Xy_train[:,trainingSetWidth]\n",
    "\n",
    "        X_test = Xy_test[:,0:trainingSetWidth]\n",
    "        y_test = Xy_test[:,trainingSetWidth]\n",
    "\n",
    "        C = C\n",
    "        gamma = gamma\n",
    "        #kernel='linear'\n",
    "\n",
    "        clf = svm.SVC(C=C, kernel=kernel) #, gamma = gamma)\n",
    "        clf.fit(X_train, y_train)  \n",
    "\n",
    "        Fx = clf.predict(X_test)\n",
    "\n",
    "        error[0,i] = (1.0/float(len(y_test)))*np.sum(np.where(Fx == y_test, 0, 1))\n",
    "\n",
    "    average_of_errors = (1.0/float(number_of_error_Calculations) )* np.sum(error)\n",
    "    \n",
    "    testing_error_for_ratios[q_iter,1] = average_of_errors\n",
    "    testing_error_for_ratios[q_iter,2] = 1 - average_of_errors\n",
    "    \n",
    "print \"Dataset:\", dataset_name\n",
    "print \"This is SVC with\", kernel,\"kernel\"#,\" and with training/testing ratio: \", trainingRatio, testingRatio\n",
    "print \"The positive label is\", posLabel, \"and the negative label is\", negLabel \n",
    "print \"C =\", C #, \" gamma =\", gamma\n",
    "print \"The number of error calculations per parameter set is\", number_of_error_Calculations \n",
    "print \"The training/testing ratio is the first column\"\n",
    "print \"The testing error average is the second column\"\n",
    "print \"The testing accuracy average is the third column\"\n",
    "print np.around(testing_error_for_ratios,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
